{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVQXa2TF9W88"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def extract_frames(video_path, output_folder, max_frames=5):\n",
        "    # Google Driveをマウント\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # ビデオファイルを開く\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # 出力フォルダが存在しない場合は作成\n",
        "    full_output_path = f\"/content/drive/MyDrive/{output_folder}\"\n",
        "    if not os.path.exists(full_output_path):\n",
        "        os.makedirs(full_output_path)\n",
        "\n",
        "    # フレームカウンタ\n",
        "    frame_count = 0\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    while frame_count < max_frames:\n",
        "        # フレームを読み込む\n",
        "        success, frame = video.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # フレームを保存\n",
        "        output_path = os.path.join(full_output_path, f\"frame_{frame_count:04d}.jpg\")\n",
        "        cv2.imwrite(output_path, frame)\n",
        "\n",
        "        # フレームを表示（Colab用）\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        frames.append(frame)\n",
        "\n",
        "    # ビデオファイルを閉じる\n",
        "    video.release()\n",
        "\n",
        "    print(f\"合計 {frame_count} フレームを抽出しました。\")\n",
        "    print(f\"フレームは {full_output_path} に保存されました。\")\n",
        "\n",
        "    return frames\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JviDtqgzPfjr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def detect_and_inpaint_faces(frame):\n",
        "    \"\"\"\n",
        "    フレームから顔を検出し、inpaintingを行う関数\n",
        "    Args:\n",
        "        frame: cv2で読み込んだ画像（numpy.ndarray）\n",
        "    Returns:\n",
        "        processed_image: 処理後の画像（numpy.ndarray）\n",
        "        face_mask: 顔領域のマスク（numpy.ndarray）\n",
        "    \"\"\"\n",
        "    # 顔検出器の読み込み\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    # グレースケールに変換\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 顔検出\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # マスクの作成（顔領域を白、それ以外を黒に）\n",
        "    face_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
        "\n",
        "    # 検出された顔領域を少し大きめに取る\n",
        "    for (x, y, w, h) in faces:\n",
        "        # マスクを少し大きめに\n",
        "        padding = int(min(w, h) * 0.1)  # パディングを10%に設定\n",
        "        x1 = max(x - padding, 0)\n",
        "        y1 = max(y - padding, 0)\n",
        "        x2 = min(x + w + padding, frame.shape[1])\n",
        "        y2 = min(y + h + padding, frame.shape[0])\n",
        "\n",
        "        # マスクに顔領域を追加\n",
        "        cv2.rectangle(face_mask, (int(x1), int(y1)), (int(x2), int(y2)), 255, -1)\n",
        "\n",
        "    # インペインティングの実行\n",
        "    processed_image = cv2.inpaint(frame, face_mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "    return processed_image, face_mask\n",
        "\n",
        "def prepare_for_imagen(image):\n",
        "    \"\"\"\n",
        "    画像をImagen APIで使用できる形式に変換する関数\n",
        "    Args:\n",
        "        image: numpy.ndarray形式の画像\n",
        "    Returns:\n",
        "        base64_image: Base64エンコードされた画像文字列\n",
        "    \"\"\"\n",
        "    # OpenCV画像をPIL形式に変換\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    pil_image = Image.fromarray(image_rgb)\n",
        "\n",
        "    # PILイメージをバイトストリームに変換\n",
        "    byte_stream = io.BytesIO()\n",
        "    pil_image.save(byte_stream, format='PNG')\n",
        "    byte_stream.seek(0)\n",
        "\n",
        "    # Base64エンコード\n",
        "    base64_image = base64.b64encode(byte_stream.getvalue()).decode('utf-8')\n",
        "\n",
        "    return base64_image\n",
        "\n",
        "def base64_to_cv2(base64_string):\n",
        "    \"\"\"\n",
        "    Base64文字列をOpenCV画像形式に変換する関数\n",
        "    \"\"\"\n",
        "    # Base64をデコード\n",
        "    img_data = base64.b64decode(base64_string)\n",
        "\n",
        "    # バイトデータをnumpy配列に変換\n",
        "    nparr = np.frombuffer(img_data, np.uint8)\n",
        "\n",
        "    # numpy配列をOpenCV画像に変換\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    return img\n",
        "\n",
        "def process_frame_for_imagen(frame):\n",
        "    \"\"\"\n",
        "    フレームを処理してImagen API用に準備する関数\n",
        "    Args:\n",
        "        frame: cv2で読み込んだ画像\n",
        "    Returns:\n",
        "        base64_processed: 処理済み画像のBase64文字列\n",
        "        base64_mask: マスクのBase64文字列\n",
        "    \"\"\"\n",
        "    # 顔検出とinpainting\n",
        "    processed_image, face_mask = detect_and_inpaint_faces(frame)\n",
        "\n",
        "    # Imagen API用にBase64エンコード\n",
        "    base64_processed = prepare_for_imagen(processed_image)\n",
        "    base64_mask = prepare_for_imagen(cv2.cvtColor(face_mask, cv2.COLOR_GRAY2BGR))\n",
        "\n",
        "    return base64_processed, base64_mask\n",
        "\n",
        "# 使用例\n",
        "def main():\n",
        "    # extract_framesで取得したフレームに対して処理を実行\n",
        "    frame = cv2.imread(\"/content/drive/MyDrive/output_frames/frame_0000.jpg\")\n",
        "\n",
        "    if frame is None:\n",
        "        print(\"画像の読み込みに失敗しました。パスを確認してください。\")\n",
        "        return\n",
        "\n",
        "    # 処理の実行\n",
        "    base64_processed, base64_mask = process_frame_for_imagen(frame)\n",
        "\n",
        "    # 処理結果の確認\n",
        "    processed_img = base64_to_cv2(base64_processed)\n",
        "    mask_img = base64_to_cv2(base64_mask)\n",
        "\n",
        "    # 結果の表示\n",
        "    print(\"処理済み画像:\")\n",
        "    cv2_imshow(processed_img)\n",
        "    print(\"\\nマスク画像:\")\n",
        "    cv2_imshow(mask_img)\n",
        "\n",
        "    return base64_processed, base64_mask\n",
        "\n",
        "# extract_frames関数で使用する場合の例\n",
        "def process_video_frame(frame):\n",
        "    \"\"\"\n",
        "    ビデオフレームを処理する関数\n",
        "    \"\"\"\n",
        "    base64_processed, base64_mask = process_frame_for_imagen(frame)\n",
        "\n",
        "    # 結果の表示（必要に応じて）\n",
        "    processed_img = base64_to_cv2(base64_processed)\n",
        "    mask_img = base64_to_cv2(base64_mask)\n",
        "\n",
        "    print(\"処理済み画像:\")\n",
        "    cv2_imshow(processed_img)\n",
        "    print(\"\\nマスク画像:\")\n",
        "    cv2_imshow(mask_img)\n",
        "\n",
        "    return base64_processed, base64_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbfjlluEXaUg",
        "outputId": "84704d62-8437-413c-8308-8b9e79d6aa53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.1.21)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.20.1\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.21)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.11)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (1.4.20)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.12.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.10.5)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.2.2)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.19->albumentations->insightface) (3.11.3)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2024.12.14)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.1.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1064899 sha256=3be7342af9bc54df94379d06db07cc4616955f757ca0c74eda766d0357813c21\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, sounddevice, mediapipe, insightface\n",
            "Successfully installed insightface-0.7.3 mediapipe-0.10.20 onnx-1.17.0 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime-gpu\n",
        "!pip install mediapipe opencv-python-headless pillow numpy insightface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05hiuG9PQPK7",
        "outputId": "82eaad57-afec-4c70-8a74-e4172436d4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "inswapper-shape: [1, 3, 128, 128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "処理中: 100%|██████████| 723/723 [15:57<00:00,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "処理が完了しました: /content/drive/MyDrive/videoconvert/output.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "import insightface\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_frames(video_path, num_frames=10):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    for i in range(num_frames):\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def display_frames(frames):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for idx, frame in enumerate(frames):\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        axes[idx].imshow(frame_rgb)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f'Frame {idx+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def process_video(source_path, video_path, output_path):\n",
        "    app = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "    model = insightface.model_zoo.get_model('/content/drive/MyDrive/videoconvert/inswapper_128.onnx')\n",
        "\n",
        "    source_img = cv2.imread(source_path)\n",
        "    source_faces = app.get(source_img)\n",
        "    if not source_faces:\n",
        "        raise ValueError(\"ソース画像から顔を検出できませんでした\")\n",
        "    source_face = source_faces[0]\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    with tqdm(total=total_frames, desc=\"処理中\") as pbar:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            target_faces = app.get(frame)\n",
        "            if target_faces:\n",
        "                result = frame.copy()\n",
        "                for target_face in target_faces:\n",
        "                    result = model.get(result, target_face, source_face, paste_back=True)\n",
        "                out.write(result)\n",
        "            else:\n",
        "                out.write(frame)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"処理が完了しました: {output_path}\")\n",
        "\n",
        "# メイン処理\n",
        "source_path = '/content/drive/MyDrive/videoconvert/hashikan2.jpeg'\n",
        "video_path = '/content/drive/MyDrive/videoconvert/raw.mov'\n",
        "output_path = '/content/drive/MyDrive/videoconvert/output.mp4'\n",
        "\n",
        "process_video(source_path, video_path, output_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}